{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/eric_records.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"description\"]].to_csv(\"eric_for_mlm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, DistilBertModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"I need papers about irrespective of language and cultural background.\"\n",
    "document2 = \"\"\"This paper presents arguments in favor of and against formalistic and realistic approaches in teaching/learning English in an English-speaking country. Within the formalism approach, the purpose of language teaching is to inculcate an intuitive grasp of the system of the target language. The ability to manipulate language rules is of prime consideration, with the ability to use language appropriately of secondary concern. Realism refers to an approach where the ability to use language in natural situations is the prime concern. A command of language forms is of interest only as it contributes to the ability to operate effectively in real-life language situations. It is suggested that language programs combine formalism (since linguistic forms must be learned through practice) and  realism (since language is an activity related to human interaction and the exchange of information). (Author/JK).\"\"\"\n",
    "# Tokenize the input text\n",
    "inputs1 = tokenizer(document, return_tensors=\"pt\",truncation=True)\n",
    "inputs2 = tokenizer(document2, return_tensors=\"pt\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model.eval()\n",
    "\n",
    "# Get the token embeddings\n",
    "with torch.no_grad():\n",
    "    outputs1 = model(**inputs1)\n",
    "    outputs2 = model(**inputs2)\n",
    "    # Get the embeddings from the last hidden layer\n",
    "    token_embeddings1 = outputs1.last_hidden_state\n",
    "    token_embeddings2 = outputs2.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask1 = inputs1['attention_mask']\n",
    "attention_mask2 = inputs2['attention_mask']\n",
    "attention_mask_expanded1 = attention_mask1.unsqueeze(-1).expand(token_embeddings1.size()).float()\n",
    "attention_mask_expanded2 = attention_mask2.unsqueeze(-1).expand(token_embeddings2.size()).float()\n",
    "sum_embeddings1 = torch.sum(token_embeddings1 * attention_mask_expanded1, 1)\n",
    "sum_embeddings2 = torch.sum(token_embeddings2 * attention_mask_expanded2, 1)\n",
    "sum_mask1 = torch.clamp(attention_mask_expanded1.sum(1), min=1e-9)\n",
    "sum_mask2 = torch.clamp(attention_mask_expanded2.sum(1), min=1e-9)\n",
    "average_embeddings1 = sum_embeddings1 / sum_mask1\n",
    "average_embeddings2 = sum_embeddings2 / sum_mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cos_sim = cosine_similarity(average_embeddings1, average_embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77956605]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
